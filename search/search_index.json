{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"SnakeSplice  greets you!","text":"<p>This is the documentation!</p> <p>Your journey into the world of efficient and effective RNA-seq analysis begins here.</p> <p>Warning</p> <p>This documentation is a work in progress.  If you have any questions or suggestions, please feel free to reach out to us.</p> <p>Tip</p> <p>SnakeSplice is a Snakemake pipeline for the analysis of RNA-seq data. It is designed to be modular and flexible, allowing users to easily customize their analysis.</p> <p>Special features:  We focus on the analysis of splicing patterns. Additionally we provide the generation of a comprehensive report.</p> <p>Join us on our journey to explore the world of RNA-seq data analysis! Your first step is to get to know the pipeline and its modules. Take a look here: Getting Started guide.</p>"},{"location":"about/","title":"About","text":"<p>Something about me?  Or just leave contact?</p> <p>TODO</p>"},{"location":"getting_started/installation/","title":"Installation","text":"<p>SnakeSplice is based on the Snakemake workflow management system.  The pipeline is written in Python and is compatible with Linux and MacOS.</p> <p>Requirements</p> <p>In order to use SnakeSplice you need to have SnakeMake installed. You can either visit the Snakemake documentation for detailed installation guidelines or use the following instructions to install Snakemake and SnakeSplice.</p>"},{"location":"getting_started/installation/#installation-via-condamamba","title":"Installation via Conda/Mamba","text":"<p>We recommend to install Snakemake and SnakeSplice via the Conda/Mamba package manager.</p>"},{"location":"getting_started/installation/#1-set-up-of-condamamba","title":"1. Set-up of Conda/Mamba","text":"<p>In order to take advantage of Mamba, an extremely fast and robust replacement for the  Conda package manager, we recommend to install the managers via the Miniforge installers. You can find them here: Miniforge Repository</p> <p>Here are the steps for Linux systems: Install Conda/Mamba<pre><code>curl -L -O \"https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh\"\nbash Miniforge3-$(uname)-$(uname -m).sh\n</code></pre></p> <p>Restart your terminal</p> <p>Don't forget to restart your terminal after the installation!</p>"},{"location":"getting_started/installation/#2-installation-of-snakemake","title":"2. Installation of Snakemake","text":"<p>After a successfull installation of Conda/Mamba, you can proceed with installing Snakemake. Install Snakemake<pre><code># Create a new environment\nmamba create -n snakemake -c conda-forge -c bioconda snakemake\n# Activate the environment\nconda activate snakemake\n</code></pre></p> <p>Verify the installation</p> <p>You can verify the installation by running <code>snakemake --version</code>.</p>"},{"location":"getting_started/installation/#3-get-snakesplice","title":"3. Get SnakeSplice","text":"<p>After the installation of Snakemake, you can proceed with installing SnakeSplice. Install SnakeSplice<pre><code># Install SnakeSplice by cloning the repository\ngit clone https://git.bihealth.org/btg/software/snakesplice.git\n# Change into the SnakeSplice directory\ncd snakesplice\n</code></pre></p> <p>The initial set-up should look now like this: </p>"},{"location":"getting_started/installation/#4-adjust-your-snakemake-profile","title":"4. Adjust your Snakemake Profile","text":"<p>Snakemake gives you the possibility to adjust the pipeline to your specific needs by using profiles. Here one can define the number of threads, the amount of memory, whether conda environments should be used, and so on...</p> <p>Default settings</p> <p>The default settings allocate 8 cores and 30GB of memory to the pipeline. If you want to change these settings, you can do so by adjusting the <code>config.yaml</code> file in the <code>profiles/profile_local</code> directory.</p> <p>For this tutorial, we will use the default settings. You can find the <code>config.yaml</code> file here.</p>"},{"location":"getting_started/installation/#5-celebrate","title":"5. Celebrate","text":"<p>You are now ready to use SnakeSplice! Please continue with the tutorial to learn how to use SnakeSplice.</p>"},{"location":"getting_started/report/","title":"SnakeSplice Report","text":""},{"location":"getting_started/tutorial_alignments/","title":"1. Step: Quality control, pre-processing and alignment","text":"<p>The first step in our tutorial is to perform quality control, pre-processing and alignment of the input data. This is done by the first module of SnakeSplice, which is called <code>module1_qc_preproc_alignment</code>.</p> <p>We decide to use the following tools for this module:</p> <ul> <li>Read trimming: Trimmomatic</li> <li>Alignment: STAR</li> <li>Quality control (Reads): Kraken2</li> <li>Quality control (Reads): FastQC (after and before trimming)</li> <li>Quality control (Alignment): Bamtools/Samtools</li> <li>Quality control (Alignment): Qualimap</li> <li>Quality control (summary): MultiQC</li> </ul>"},{"location":"getting_started/tutorial_alignments/#11-main-configuration-file","title":"1.1 Main configuration file","text":"<p>In order to run the first module and only the first module, you need to adjust the main configuration file <code>config_files/config_main.yaml</code>.</p> <p>You can choose an abitrary name for your project by setting the <code>run_identifier</code> variable. Then set all module switches to <code>False</code> except for the first module. An excerpt of an example configuration file is shown below:</p> config_main.yaml<pre><code>[...]\nglobal_variable:\n  run_identifier: \"tutorial_run\"\n\n[...]\nmodule_switches:\n  # ------- 1.0 Module: Report Generation ---------\n  run_module0_report_generation: False\n\n  # ------- 1.1 Module: Quality-Control, Preprocessing, and Alignment --------\n  run_module1_qc_preprocessing_and_alignment: True\n\n  # ------- 1.2 Module: Detection of gene fusion events ---------\n  run_module2_gene_fusion_detection: False\n\n  # ------- 1.3 Module: Detection and Quantification of gene products (transcripts) and analysis ---------\n  run_module3_gene_expression_quantification_and_analysis: False\n\n  # ------- 1.4 Module: Splicing Patterns Analysis ---------\n  run_module4_splicing_pattern_analysis: False\n[...]\n</code></pre> <p>The complete configuration file for this example can be downloaded here: config_main.yaml. Make sure to have this file saved under <code>config_files/config_main.yaml</code> in your project directory.</p>"},{"location":"getting_started/tutorial_alignments/#12-module-configuration-file","title":"1.2 Module configuration file","text":"<p>In order to specify which tools and parameters are used for the first module, you need to adjust the module configuration file <code>config_files/config_module1_qc_preproc_alignment.yaml</code>. This configuration file is located in the <code>config_files</code> directory.</p> <p>Make sure to only switch on the tools of your choice. Also, since we are using STAR for alignment and know that our data is sampled from the 21. chromosome of the human genome, we need to specify the reference genome build accordingly (GRCh38_chr21). The other options can be left as they are.</p> <p>An excerpt of the configuration file with the relevant settings is shown below:</p> config_module1_qc_preproc_alignment.yaml<pre><code>[...]\n\n# ------- 1.1 Module: Quality-Control, Preprocessing, and Alignment --------\nmodule1_qc_preprocessing_and_alignment_settings:\n  switch_variables:\n    # Switch variables to decide which features are to be included\n    run_check_of_strandedness: False      # Run python script to check strandedness of input read files\n    run_trimmomatic: True                # Run trimmomatic: Quality trimming of input reads\n    run_kraken2: True                    # Run Kraken2: Check for potential contamination via Kraken2\n    run_fastqc_before_trimming: True      # Run fastqc: Quality control of input reads before trimming\n    run_fastqc_after_trimming: True       # Run fastqc: Quality control of input reads after trimming\n    run_alignment:\n      use_star: True                     # Run STAR alignment: Align reads to reference genome\n      use_olego: False                    # Run Olego alignment: Align reads to reference genome\n    run_bamstats: True                  # Run bamstats: Quality control of aligned reads\n    run_qualimap: True                   # Run Qualimap: Quality control of alignment results\n    run_deeptools: False                  # Run deeptools: Quality control of alignment results\n    run_multiqc: True                     # Run multiqc: Summarize all quality control results into one output-file\n[...]\n\n# 2.5 Alignments\n  alignment_settings:\n    # 2.5.1 STAR alignment: Align reads to reference genome\n    star_alignment_settings:\n      # Reference genome sequence file, that is used to create the STAR index\n      reference_genome_build:\n        \"GRCh38_chr21\"\n[...]\n</code></pre> <p>To follow this tutorial you can use the <code>config_module1_qc_preproc_alignment.yaml</code> file as is provided through the SnakeSplice repository. However, the example configuration file can also be downloaded here: config_module1_qc_preproc_alignment.yaml.</p>"},{"location":"getting_started/tutorial_alignments/#13-execution","title":"1.3 Execution","text":"<p>Now that we have set up the main and module configuration files, we can execute the first module by running the SnakeSplice pipeline. But let's first make a quick check if everything is set up correctly. To do so, navigate to the main directory (<code>snakesplice</code>) of SnakeSplice and execute a dry run: Dry run<pre><code>snakemake --profile profiles/profile_local/ -n\n</code></pre></p> <p>You should see a list of all rules that would be executed if you would run the pipeline. In total 152 rule executions should be listed.</p> <p>If this is the case, you can now execute the pipeline. To do so run the following command:</p> Run the pipeline<pre><code>snakemake --profile profiles/profile_local/\n\n# Or if you want to use a specific number of cores\nsnakemake --profile profiles/profile_local/ --cores 4\n\n# Run the pipeline in the background\nnohup snakemake --profile profiles/profile_local/ &amp;\n\n# Run pipeline in background &amp; write logs to a specified file\nnohup snakemake --profile profiles/profile_local &amp;&gt; output-$(date +\"%Y-%m-%dT%H-%M-%S\").txt &amp;\n</code></pre>"},{"location":"getting_started/tutorial_alignments/#14-results-html-report","title":"1.4 Results &amp; HTML report","text":"<p>The results of the pipeline are stored in the directory <code>output</code>. Each module has its own subdirectory (names corresponding to your settings in <code>config_main.yaml</code>) in which the results of its respective tools (subdir names are defined in <code>config_module1_qc_preproc_alignment.yaml</code>) are saved. Feel free to explore the results directly in your file system. However, indeed the most convenient way to explore the results is to use our HTML report.</p> <p>Tip</p> <p>Normally, the generation of the HTML report is performed at the very end when results from all modules are available. Though, if you already want to have a look at the results of the first module, you can generate the HTML report by  setting up and executing the 0. module.</p> <p>Otherwise you can skip this step and proceed with the second module.</p> <p>To generate the HTML report, you need to simply switch on the 0. module in the main configuration file <code>config_main.yaml</code> and execute the pipeline again.</p> config_main.yaml<pre><code>[...]\n\nmodule_switches:\n  # ------- 1.0 Module: Report Generation ---------\n  run_module0_report_generation: True\n\n  # ------- 1.1 Module: Quality-Control, Preprocessing, and Alignment --------\n  run_module1_qc_preprocessing_and_alignment: True\n\n  # ------- 1.2 Module: Detection of gene fusion events ---------\n  run_module2_gene_fusion_detection: False\n[...]\n</code></pre> <p>After the execution of the pipeline, you can find the HTML report in the output directory of the 0. module. If you have kept the default settings, then the HTML report is located in the  <code>output/module0_report_generation/output/snakesplice_reports/&lt;condition&gt;.html</code>.</p>"},{"location":"getting_started/tutorial_alignments/#15-troubleshooting","title":"1.5 Troubleshooting","text":"<p>Here are some issues that might occur during the execution of first module of the pipeline:</p> <p>Problems during Conda environment creation Your might encounter an error message like this:</p> Error message<pre><code>[...]\nCreateCondaEnvironmentException:\nCould not create conda environment from /home/kuechleo/snakesplice/modules/SM1_module_qc_preproc_and_alignment/rules/../envs/check_strandedness_env.yaml\n[...]\nYour conda installation is not configured to use strict channel priorities. This is however crucial for having robust and correct environments (for details, see https://conda-forge.org/docs/user/tipsandtricks.html). Please consider to configure strict priorities by executing 'conda config --set channel_priority strict'.\n</code></pre> <p>Possible solutions: </p> <ol> <li>Suggestion: Please set strict channel priorities by executing <code>conda config --set channel_priority strict</code> as suggested in the error message.</li> <li>Error details: <code>configure: error: zlib development files not found</code> Solution: Install zlib development files by running <code>sudo apt-get install zlib1g-dev</code> or <code>sudo dnf install zlib-devel</code>.</li> <li>Error details: <code>configure: error: libbzip2 development files not found</code>: Solution: Install libbzip2 development files by running <code>sudo apt-get install libbz2-dev</code> or <code>sudo dnf install bzip2-devel</code>.</li> </ol>"},{"location":"getting_started/tutorial_alignments/#16-celebrate","title":"1.6 Celebrate","text":"<p>Congratulations!</p> <p>You have successfully executed the first module of SnakeSplice and even inspected the results.  You're on a good way to become a SnakeSplice expert!</p> <p>Let's proceed with the second module: Detection of gene fusion events.</p>"},{"location":"getting_started/tutorial_data/","title":"Tutorial - Data &amp; Introduction","text":"<p>This tutorial will guide you through the SnakeSplice pipeline. If you haven't installed SnakeSplice yet, please follow the installation instructions first. If you are completely new to the workflow system Snakemake, we recommend you to have a look at the Snakemake documentation.</p>"},{"location":"getting_started/tutorial_data/#example-data","title":"Example data","text":"<p>We provide example data for testing SnakeSplice. It contains simulated RNA-seq data for a control group and three case groups. All samples are from chromosome 21 of the human genome. You can download the data from here:</p> <ul> <li>Control samples: FASTQ files</li> <li>Case 1 samples: FASTQ files</li> <li>Case 2 samples: FASTQ files</li> <li>Case 3 samples: FASTQ files</li> </ul> <p>In this tutorial we will use the control samples and the case 1 samples.</p>"},{"location":"getting_started/tutorial_data/#extracting-the-data","title":"Extracting the data","text":"<p>Prerequisite: You need to have downloaded the example data (the Control samples &amp; Case 1 samples) from the links above. Save the data in a directory of your choice.  </p> <p>Now: Extract the files from the corresponding archives. To follow this tutorial please run following commands (here case1 is used as an example):</p> Extracting the data<pre><code># Change to your SnakeSplice directory (the \n# cloned SnakeSplice repository)\ncd snakesplice\n\n# Create a new directory for the example data\ncd input_data\n\n# unpack the downloaded data\ntar -xzf /path/to/simulated_reads_chr21_controls.tar.gz -C .\ntar -xzf /path/to/simulated_reads_chr21_case1.tar.gz -C .\n</code></pre> <p>Now you should have two novel directories in your <code>input_data</code> directory, one for the control samples and one for the case samples.</p>"},{"location":"getting_started/tutorial_data/#metadata-file","title":"Metadata file","text":"<p>The metadata file is a CSV (Comma Separated Values) file that contains information about the samples. It is used to link the samples to the corresponding groups and conditions. You can place the metadata file anywhere on your system, but we recommend to place it in the <code>input_data</code> directory.</p> <p>Attributes:</p> Column name Description Example sample_name Name of the sample \"sample1\" sample_directory Path to the directory containing the sample \"path/to/sample1\" or \"some_variable\" (some_variable must be defined in PEP config file) read1 Name of the first read file \"sample1_R1.fastq\" read2 Name of the second read file \"sample1_R2.fastq\" control <code>true</code> if sample is control sample or <code>false</code> if not <code>true</code> condition Name of the condition, or None if control sample <code>condition1</code> stranded Strandedness of the library \"reverse\" adaptors_file Path to the file containing the adaptors \"path/to/adaptors.fa\" or \"some_variable\" (some_variable must be defined in the PEP config file) <p>To follow this tutorial you can use the CSV-file as is provided through the SnakeSplice repository (<code>input_data/input_metadata.csv</code>). However, the example metadata CSV-file can also be downloaded here: Download CSV.</p>"},{"location":"getting_started/tutorial_data/#pep-files","title":"PEP files","text":"<p>The SnakeSplice pipeline uses the Portable Encapsulated Project (PEP) format to define the metadata file and to set variables that are used in the metadata file. The file <code>pep/pep_config.yaml</code> is used to identify which file is used as metadata file for our execution and to define variables that are can be referenced in the metadata file.</p> <p>Changeable attributes (ignore the rest for now):</p> YAML directive Description Example sample_table Path to the metadata file (relative to this YAML file) \"../input_data/input_metadata.csv\" sources Variables that are used in the metadata file in the columns sample_directory and adaptors_file <code>adaptors_file: \"path/to/adaptors.fa\"</code> <p>To follow this tutorial you can use the <code>pep_config.yaml</code> file as is provided through the SnakeSplice repository. However, the example PEP file can also be downloaded here: Download PEP.</p>"},{"location":"getting_started/tutorial_data/#configuration-files","title":"Configuration files","text":"<p>Here we will shortly discuss the structure of the configuration files that are used to control the SnakeSplice pipeline. However, this is just to give you an overview of the files and their purpose. We will come back to the configuration files later in the tutorial.</p>"},{"location":"getting_started/tutorial_data/#main-configuration-file","title":"Main configuration file","text":"<p>The main configuration file for SnakeSplice is called <code>config_main.yaml</code> and is located in the SnakeSplice directory under <code>config_files</code>. It defines a name for the project, controls which modules are executed, and sets the paths to the output directories of the respective modules.</p> <p>Atttributes:</p> YAML directive Description Example run_identifier Name of the project \"tutorial_run\" module_switches Each module has its own entry here, where the values <code>True</code> and <code>False</code> signal whether to execute a specific module or not <code>True</code> module_output_dir_names The paths to the output directories of the respective modules \"output/module1_qc_preproc_and_alignment\""},{"location":"getting_started/tutorial_data/#module-configuration-files","title":"Module configuration files","text":"<p>Since SnakeSplice is divided into multiple modules, each module has its own configuration file:</p> <ul> <li><code>config_module1_qc_preproc_alignment.yaml</code></li> <li><code>config_module2_gene_fusion.yaml</code></li> <li><code>config_module3_gene_expression_quantification_and_analysis_settings.yaml</code></li> <li><code>config_module4_splicing_patterns_analysis.yaml</code></li> <li><code>config_files/config_module5_variant_calling.yaml</code></li> </ul> <p>Atttributes:</p> YAML directive Description Example switch_variables Each tool has its own entry here, where the values <code>True</code> and <code>False</code> signal whether to execute a specific tool <code>True</code> output directories The name of the output folder for a specific tool <code>multiqc_output_dir: \"multiqc\"</code> tool-specific parameters The parameters for a specific tool <code>file_kraken2_db: \"path/to/kraken2_db\"</code> module-specific parameters The parameters for a specific module <code>reference_transcriptome_build: \"GRCh38_chr21\"</code>"},{"location":"getting_started/tutorial_data/#summary","title":"Summary","text":"<p>After having followed the instructions above, your file structure should look like this (compare with <code>tree -L 2</code>):</p> <p></p>"},{"location":"getting_started/tutorial_data/#celebrate","title":"Celebrate","text":"<p>You have successfully obtained the data necessary for this tutorial. Great! So let's move on to the next step: Quality control, pre-processing and alignment.</p>"},{"location":"getting_started/tutorial_gene_expression/","title":"3. Step: Gene Expression Analysis","text":"<p>Now we get to the third module of SnakeSplice, which is called <code>module3_gene_expression_quantification_and_analysis</code>.</p> <p>Here we want to identify and quantify differentially expressed genes and perform a basic analysis of the gene expression data. Additionally, SnakeSplice includes the possibility to extract enriched or depleted gene sets by performing a gene set enrichment analysis (GSEA).</p> <p>Required input</p> <p>While the pseudo-alignment tools (i.e. Salmon, Kallisto, and RSEM) do not rely on BAM files  (the first module's output), the expression outlier detection tool OUTRIDER does!</p> <p>Thus, if you want to include OUTRIDER be aware that you need to have successfully executed the first module. Alternatively you can provide the necessary input BAM files and specify their location in the configuration file.</p> <p>Required input files for OUTRIDER: BAM files (aligned reads) from the first module.</p> <p>In this part of the tutorial we will use the following tools for this module:</p> <ul> <li>Salmon: Salmon is a tool for quantifying the expression of transcripts from RNA-Seq data.</li> <li>DESeq2: DESeq2 is a tool for differential gene expression analysis.</li> <li>GSEA: Gene Set Enrichment Analysis (GSEA) is a computational method that determines whether an a priori defined set of genes shows statistically significant, concordant differences between two biological states.</li> </ul>"},{"location":"getting_started/tutorial_gene_expression/#31-main-configuration-file","title":"3.1 Main configuration file","text":"<p>Same procedure as every time: In order to run the third module, you need to adjust the main configuration file <code>config_files/config_main.yaml</code>. Simply switch on the third module.</p> config_main.yaml<pre><code>[...]\nglobal_variable:\n  run_identifier: \"tutorial_run\"\n\n[...]\nmodule_switches:\n  # ------- 1.0 Module: Report Generation ---------\n  run_module0_report_generation: False\n\n  # ------- 1.1 Module: Quality-Control, Preprocessing, and Alignment --------\n  run_module1_qc_preprocessing_and_alignment: True\n\n  # ------- 1.2 Module: Detection of gene fusion events ---------\n  run_module2_gene_fusion_detection: False\n\n  # ------- 1.3 Module: Detection and Quantification of gene products (transcripts) and analysis ---------\n  run_module3_gene_expression_quantification_and_analysis: True\n\n  # ------- 1.4 Module: Splicing Patterns Analysis ---------\n  run_module4_splicing_pattern_analysis: False\n[...]\n</code></pre> <p>The complete configuration file for this example can be downloaded here: config_main.yaml. Make sure to have this file saved under <code>config_files/config_main.yaml</code> in your project directory.</p>"},{"location":"getting_started/tutorial_gene_expression/#32-module-configuration-file","title":"3.2 Module configuration file","text":"<p>Let's specify the parameters for the third module by adjusting the module configuration file <code>config_files/config_module3_gene_expression.yaml</code>: Make sure to switch on Salmon and the overall summary, which summarizes this module's results.</p> <p>Reference transcriptome build</p> <p>Remember: We only need to reference the 21. chromosome (GRCh38_chr21). Thus, we can set \"GRCh38_chr21\" under <code>reference_transcriptome_build</code>.</p> <p>Use trimmed FASTQ files</p> <p>Since we have used Trimmomatic in our first pipeline's module, we can set <code>use_trimmed_fastq_files</code> to <code>True</code>. SnakeSplice will then automatically find the trimmed FASTQ files and use them as input for Salmon.</p> <p>An excerpt of the configuration file with the relevant settings is shown below:</p> config_module3_gene_expression.yaml<pre><code>[...]\n# =============== Configuration file for module: Detection and quantification =============\n# Use this config-file to switch on/off the features that you need for your personal research.\n# Furthermore, you can set the detailed parameters for the respective features.\n\n\nmodule3_gene_expression_quantification_and_analysis_settings:\n  # =============== 1.1 Switch variables =============\n  switch_variables:\n    run_outrider_analysis:    False   # Run Outrider analysis: Identifies gene expression outliers\n    run_salmon_analysis:      True    # Run salmon analysis: Quantifies transcripts\n    run_kallisto_analysis:    False   # Run kallisto analysis: Quantifies transcripts\n    run_rsem_analysis:        False   # Run rsem analysis: Quantifies transcripts &amp; gene expression\n    run_mae_analysis:         False   # Run mae analysis: Detects mono-allelic expression\n\n    run_overall_summary:      True\n\n[...]\n\n  # Reference transcritpome build\n  # ATTENTION: Currently, only GRCh38 is supported\n  reference_transcriptome_build:\n    \"GRCh38_chr21\"          # \"GRCh37\" or \"GRCh38\" or \"GRCh38_chr21\" (for testing purposes)\n\n  # Whether to use the trimmed FASTQ files as input for the quantification tools\n  # If yes: The trimmed FASTQ files created by the QC &amp; Preprocessing module are used as input [Trimmomatic output]\n  use_trimmed_fastq_files:  \n    True                # Either True or False\n\n[...]\n\n  # --------- 2.2 Salmon settings ---------\n  salmon_settings:\n    # Whether to include a Gene Set Enrichment Analysis (GSEA)\n    run_gse_analysis:\n      True\n[...]\n</code></pre> <p>To follow this tutorial you can use the <code>config_module3_gene_expression.yaml</code> file as is provided through the SnakeSplice repository. However, the example configuration file can also be downloaded here: config_module3_gene_expression.yaml.</p>"},{"location":"getting_started/tutorial_gene_expression/#33-execution","title":"3.3 Execution","text":"<p>Superb! We have set up the main and module configuration files for the third module. Now we can continue with the execution of the SnakeSplice pipeline.</p> <p>But let's first make a quick check if everything is set up correctly. To do so, navigate to the main directory (<code>snakesplice</code>) of SnakeSplice and execute a dry run:</p> Dry run<pre><code>snakemake --profile profiles/profile_local/ -n\n</code></pre> <p>You should see a list of all rules that would be executed if you would run the pipeline. If the dry run was successful, you can execute the pipeline by running the following command:</p> Execution<pre><code>snakemake --profile profiles/profile_local/\n\n# Alternative: Run pipeline in background &amp; write logs to a specified file\nnohup snakemake --profile profiles/profile_local &amp;&gt; output-$(date +\"%Y-%m-%dT%H-%M-%S\").txt &amp;\n</code></pre>"},{"location":"getting_started/tutorial_gene_expression/#34-results-html-report","title":"3.4 Results &amp; HTML report","text":"<p>By default the results of the second module are stored in the <code>output/module3_gene_expression_quantification_and_analysis/output/</code> directory. Feel free to explore the results directly in your file system.</p>"},{"location":"getting_started/tutorial_gene_expression/#35-troubleshooting","title":"3.5 Troubleshooting","text":"<p>Here are some issues that might occur during the execution of first module of the pipeline:</p> <p>TODO</p>"},{"location":"getting_started/tutorial_gene_expression/#36-celebrate","title":"3.6 Celebrate","text":"<p>Yippie! The third module of SnakeSplice is now running and will provide you with an analysis of the gene expression data. Wonderful!</p> <p>Please continue with the tutorial to learn how to use SnakeSplice for splicing pattern analysis: Analysis of splicing patterns.</p>"},{"location":"getting_started/tutorial_gene_fusions/","title":"2. Step: Detection of Gene Fusion Events","text":"<p>In this part of the turorial we will focus on the detection of gene fusion events. This is achieved by the second module of SnakeSplice, which is called <code>module2_gene_fusion_detection</code>.</p> <p>Required input</p> <p>To be able to execute the second module, you need to have successfully executed the first module. Or you need to provide the necessary input BAM files and specify their location in the configuration file.</p> <p>Required input files: BAM files (aligned reads) from the first module.</p> <p>We decide to use the following tool for this module:</p> <ul> <li>Arriba: Arriba is a tool for gene fusion detection in RNA-Seq data.</li> </ul>"},{"location":"getting_started/tutorial_gene_fusions/#21-main-configuration-file","title":"2.1 Main configuration file","text":"<p>In order to run the second module, you need to adjust the main configuration file <code>config_files/config_main.yaml</code>. Keep the settings of the first module as they are but also switch on the second module. An excerpt of an example configuration file is shown below:</p> config_main.yaml<pre><code>[...]\nglobal_variable:\n  run_identifier: \"tutorial_run\"\n\n[...]\nmodule_switches:\n  # ------- 1.0 Module: Report Generation ---------\n  run_module0_report_generation: False\n\n  # ------- 1.1 Module: Quality-Control, Preprocessing, and Alignment --------\n  run_module1_qc_preprocessing_and_alignment: True\n\n  # ------- 1.2 Module: Detection of gene fusion events ---------\n  run_module2_gene_fusion_detection: True\n\n  # ------- 1.3 Module: Detection and Quantification of gene products (transcripts) and analysis ---------\n  run_module3_gene_expression_quantification_and_analysis: False\n\n  # ------- 1.4 Module: Splicing Patterns Analysis ---------\n  run_module4_splicing_pattern_analysis: False\n[...]\n</code></pre> <p>The complete configuration file for this example can be downloaded here: config_main.yaml. Make sure to have this file saved under <code>config_files/config_main.yaml</code> in your project directory.</p>"},{"location":"getting_started/tutorial_gene_fusions/#22-module-configuration-file","title":"2.2 Module configuration file","text":"<p>Let's specify arriba's parameters by adjusting the module configuration file <code>config_files/config_module2_gene_fusion.yaml</code>. Make sure to switch on the Arriba tool and specify the location of the input BAM files.</p> <p>Input BAM files</p> <p>If you have executed the first module, you can simply put <code>star</code> as <code>input_dir_of_bam_files</code> and SnakeSplice will automatically find the BAM files generated by STAR.</p> <p>Reference genome build</p> <p>Remember: We only need to reference the 21. chromosome (GRCh38_chr21).</p> <p>Other options can be left as they are.</p> <p>Arriba Black list</p> <p>Though if you would like to you can download arriba's optional black list and reference it in the configuration file. That list is not necessary for the pipeline to run, but is highly recommended to use it.</p> <p>An excerpt of the configuration file with the relevant settings is shown below:</p> config_module2_gene_fusion.yaml<pre><code>[...]\n# =============== 1. Module: Gene Fusion Detection - Primary settings =============\nmodule2_gene_fusion_detection_settings:\n\n # ------- 1.1 Tool Switches --------\n  switch_variables:\n    run_fusion_detection_with_arriba: True        # Detect gene fusion events with Arriba\n\n  # =============== 1.2 Output directories =============\n  # The output directories for the respective tool-outputs are defined here.\n  # This is important for importing the outputs into the GUI\n  output_directories:\n    arriba_output_dir: \"arriba\"\n[...]\n\n  input_dir_of_bam_files:\n    \"star\"\n\n  # Attributes of aligned files (input BAM files)\n  bam_files_attributes:\n    # Reference genome build that was used to create the input BAM files\n    reference_genome_build:\n      \"GRCh38_chr21\"          # \"GRCh37\" or \"GRCh38\" or \"GRCh38_chr21\" (for testing purposes)\n[...]\n</code></pre> <p>To follow this tutorial you can use the <code>config_module2_gene_fusion.yaml</code> file as is provided through the SnakeSplice repository. However, the example configuration file can also be downloaded here: config_module2_gene_fusion.yaml.</p>"},{"location":"getting_started/tutorial_gene_fusions/#23-execution","title":"2.3 Execution","text":"<p>We have set up the main and module configuration files for the second module. Now we can execute the SnakeSplice pipeline again, which will let us generate an analysis  of potential gene fusion events.</p> <p>But let's first make a quick check if everything is set up correctly. To do so, navigate to the main directory (<code>snakesplice</code>) of SnakeSplice and execute a dry run: Dry run<pre><code>snakemake --profile profiles/profile_local/ -n\n</code></pre></p> <p>You should see a list of all rules that would be executed if you would run the pipeline. After the dry run, you can execute the pipeline by running the following command:</p> Execution<pre><code>snakemake --profile profiles/profile_local/\n\n# Alternative: Run pipeline in background &amp; write logs to a specified file\nnohup snakemake --profile profiles/profile_local &amp;&gt; output-$(date +\"%Y-%m-%dT%H-%M-%S\").txt &amp;\n</code></pre>"},{"location":"getting_started/tutorial_gene_fusions/#24-results-html-report","title":"2.4 Results &amp; HTML report","text":"<p>By default the results of the second module are stored in the <code>output/module2_gene_fusion_detection/output/</code> directory . Feel free to explore the results directly in your file system.</p>"},{"location":"getting_started/tutorial_gene_fusions/#25-troubleshooting","title":"2.5 Troubleshooting","text":"<p>Here are some issues that might occur during the execution of first module of the pipeline:</p> <p>TODO</p>"},{"location":"getting_started/tutorial_gene_fusions/#26-celebrate","title":"2.6 Celebrate","text":"<p>Congratulations! You have successfully executed the second module of SnakeSplice and identified potential gene fusion events.</p> <p>You can now proceed with the third module: Detection and Quantification of gene products (transcripts) and analysis.</p>"},{"location":"getting_started/tutorial_report_generation/","title":"The last step: Report generation","text":"<p>We are almost done! The last module of SnakeSplice is a special one. It is the module that provides you with the final report of the SnakeSplice pipeline. Ain't that exciting?</p> <p>This module is referenced as <code>module0_report_generation</code>. Its job is to collect the results of the previous modules and to create a comprehensive report that summarizes the findings of the SnakeSplice pipeline.</p> <p>Required input</p> <p>While this module can be run independently, it is important to note that it makes only sense to run this module if you have successfully executed (some) other modules.</p> <p>Required input files: None required, yet as many as possible recommended.</p>"},{"location":"getting_started/tutorial_report_generation/#51-main-configuration-file","title":"5.1 Main configuration file","text":"<p>Here we go again: In order to run the last module, you need to adjust the main configuration file <code>config_files/config_main.yaml</code>. Simply switch on the last/first module and keep all other modules switched on as well.</p> <p>Module selection</p> <p>All modules that you want to include in the report need to be switched on in the main configuration file.</p> <p>Note: The report can only be generated if the respectively selected modules have been executed before. Also make sure that the summary reports are switched on in the respective module configuration files.</p> config_main.yaml<pre><code>[...]\nglobal_variable:\n  run_identifier: \"tutorial_run\"\n\n[...]\nmodule_switches:\n  # ------- 1.0 Module: Report Generation ---------\n  run_module0_report_generation: True\n\n  # ------- 1.1 Module: Quality-Control, Preprocessing, and Alignment --------\n  run_module1_qc_preprocessing_and_alignment: True\n\n  # ------- 1.2 Module: Detection of gene fusion events ---------\n  run_module2_gene_fusion_detection: True\n\n  # ------- 1.3 Module: Detection and Quantification of gene products (transcripts) and analysis ---------\n  run_module3_gene_expression_quantification_and_analysis: True\n\n  # ------- 1.4 Module: Splicing Patterns Analysis ---------\n  run_module4_splicing_pattern_analysis: True\n[...]\n</code></pre> <p>The complete configuration file for this example can be downloaded here: config_main.yaml. Make sure to have this file saved under <code>config_files/config_main.yaml</code> in your project directory.</p>"},{"location":"getting_started/tutorial_report_generation/#52-module-configuration-file","title":"5.2 Module configuration file","text":"<p>This module does not require a module configuration file.</p>"},{"location":"getting_started/tutorial_report_generation/#53-execution","title":"5.3 Execution","text":"<p>Hyperfantastic! We are ready to generate our final summary reports.</p> <p>But wait! To guarantee that the report is generated correctly, we need to make sure that no old reports and  HTML files are blocking the generation of the new report. To do so, please navigate to the main directory (<code>snakesplice</code>) of SnakeSplice and execute  the following command to remove all old reports and HTML files:</p> Remove old reports<pre><code># 1. Navigate to the main directory of SnakeSplice\n# 2. Call the shell script to remove old reports\nbash scripts/remove_all_reports.sh\n</code></pre> <p>Now all old reports and HTML files have been removed and we can proceed with the execution of the last module. Let's continue by making a quick check to see whether everything is set up correctly.</p> Dry run<pre><code>snakemake --profile profiles/profile_local/ -n\n</code></pre> <p>You should see a list of all rules that would be executed if you would run the pipeline. If the dry run was successful, you can execute the pipeline by running the following command:</p> Execution<pre><code>snakemake --profile profiles/profile_local/\n\n# Alternative: Run pipeline in background &amp; write logs to a specified file\nnohup snakemake --profile profiles/profile_local &amp;&gt; output-$(date +\"%Y-%m-%dT%H-%M-%S\").txt &amp;\n</code></pre>"},{"location":"getting_started/tutorial_report_generation/#54-results-html-report","title":"5.4 Results &amp; HTML report","text":"<p>By default the results of the last module are stored in the <code>output/module0_report_generation/output/snakesplice_reports/</code> directory. You will find there for each condition a separate directory with a comprehensive report in HTML format. Please open it in your web browser to explore the results.</p>"},{"location":"getting_started/tutorial_report_generation/#55-troubleshooting","title":"5.5 Troubleshooting","text":"<p>Here are some issues that might occur during the execution of the pipeline:</p> <p>TODO</p>"},{"location":"getting_started/tutorial_report_generation/#56-celebrate","title":"5.6 Celebrate","text":"<p>Woohoo! We made it to the end of the SnakeSplice pipeline. Amazing work!</p> <p>You have now successfully executed the SnakeSplice pipeline and generated a comprehensive report that summarizes the findings of the SnakeSplice pipeline. Please take your time to explore the report and to get familiar with the results.</p>"},{"location":"getting_started/tutorial_splicing/","title":"4. Step: Splicing Patterns Analysis","text":"<p>Welcome to the fourth and most important module, <code>module4_splicing_pattern_analysis</code>. This module is the core of SnakeSplice and provides a comprehensive analysis of the splicing patterns in your RNA-Seq data.</p> <p>Required input</p> <p>The splicing pattern analysis requires the output of the first module (BAM files). Alternatively you can provide the necessary input BAM files and specify their location in the configuration file.</p> <p>Required input: BAM files (aligned reads) from the first module.</p> <p>In this part of the tutorial we will use the following tools for this module:</p> <ul> <li>rMATS: rMATS is a tool for differential splicing analysis.</li> <li>LeafCutter: LeafCutter is a tool for splicing quantitative trait loci (sQTL) analysis.</li> <li>PJD-Tool: PJD-Tool is a tool for the identification of private splice junctions.</li> <li>Whippet: Whippet is a tool for the identification of alternative splicing events.</li> </ul>"},{"location":"getting_started/tutorial_splicing/#41-main-configuration-file","title":"4.1 Main configuration file","text":"<p>The known procedure applies: To run the fourth module, you need to adjust the main configuration file <code>config_files/config_main.yaml</code>. Simply switch on the fourth module.</p> config_main.yaml<pre><code>[...]\nglobal_variable:\n  run_identifier: \"tutorial_run\"\n\n[...]\nmodule_switches:\n  # ------- 1.0 Module: Report Generation ---------\n  run_module0_report_generation: False\n\n  # ------- 1.1 Module: Quality-Control, Preprocessing, and Alignment --------\n  run_module1_qc_preprocessing_and_alignment: True\n\n  # ------- 1.2 Module: Detection of gene fusion events ---------\n  run_module2_gene_fusion_detection: False\n\n  # ------- 1.3 Module: Detection and Quantification of gene products (transcripts) and analysis ---------\n  run_module3_gene_expression_quantification_and_analysis: False\n\n  # ------- 1.4 Module: Splicing Patterns Analysis ---------\n  run_module4_splicing_pattern_analysis: True\n[...]\n</code></pre> <p>The complete configuration file for this example can be downloaded here: config_main.yaml. Make sure to have this file saved under <code>config_files/config_main.yaml</code> in your project directory.</p>"},{"location":"getting_started/tutorial_splicing/#42-module-configuration-file","title":"4.2 Module configuration file","text":"<p>In addition to switching the respective tools on, SnakeSplice provides the possibility to adjust the parameters for the splicing pattern analysis in the module configuration file <code>config_files/config_module4_splicing_pattern_analysis.yaml</code>.</p> <p>So let's specifcy the parameters for the fourth module! Make sure to switch on rMATS, LeafCutter, PJD-Tool, Whippet, and the overall summary, which summarizes this module's results.</p> <p>Reference transcriptome build</p> <p>Remember: We only need to reference the 21. chromosome (GRCh38_chr21). Thus, we can set \"GRCh38_chr21\" under <code>reference_transcriptome_build</code>.</p> <p>BAM files</p> <p>The integrated splice analysis tools rely on BAM files (aligned reads) from the first module. If you have not executed the first module, you can provide the necessary input BAM files and specify their location in the configuration file.</p> <p>If you followed the tutorial from the beginning, you can use the BAM files from the first module. Thus: <code>input_dir_of_bam_files: \"star\"</code></p> <p>An excerpt of the configuration file with the relevant settings is shown below:</p> <p>config_module4_splicing_pattern_analysis.yaml<pre><code>[...]\n\nmodule4_splicing_patterns_analysis_settings:\n  # =============== 1. Module wide settings =============\n\n  # =============== 1.1 Switch variables =============\n  switch_variables:\n    run_dexseq_analysis: False\n    run_fraser_analysis: False\n    run_irfinder_analysis: False\n    run_leafcutter_analysis: True\n    run_leafcutter_md_analysis: False\n    run_private_junction_detection: True\n    run_rmats: True\n    run_whippet: True\n\n    run_overall_summary: True\n\n[...]\n\n  input_dir_of_bam_files:\n    \"star\"\n\n  # Attributes of aligned files (input BAM files)\n  bam_files_attributes:\n    # Reference genome build that was used to create the input BAM files\n    reference_genome_build:\n      \"GRCh38_chr21\"          # \"GRCh37\" or \"GRCh38\" or \"GRCh38_chr21\" (for testing purposes)\n\n    filename_extension:   # File extension of the input BAM files\n      \".sorted.bam\"\n    sorted:\n      \"position\"      # Either position (for position-sorted) or name (for name-sorted)\n\n[...]\n</code></pre> To follow this tutorial you can use the <code>config_module4_splicing_pattern_analysis.yaml</code> file as is provided through the SnakeSplice repository. However, the example configuration file can also be downloaded here: config_module4_splicing_pattern_analysis.yaml.</p> <p>Adjust tool parameters</p> <p>You want chagne the false discovery rate (FDR) for the rMATS analysis or increase the minimum number of reads for the LeafCutter analysis? No problem! You can adjust the parameters for the respective tools in the module configuration file.</p>"},{"location":"getting_started/tutorial_splicing/#43-execution","title":"4.3 Execution","text":"<p>Magnificent! We managed to set up the main and module configuration files for the fourth module. Now we can continue with the execution of the SnakeSplice pipeline.</p> <p>But let's first make a quick check if everything is set up correctly. To do so, navigate to the main directory (<code>snakesplice</code>) of SnakeSplice and execute a dry run:</p> Dry run<pre><code>snakemake --profile profiles/profile_local/ -n\n</code></pre> <p>You should see a list of all rules that would be executed if you would run the pipeline. If the dry run was successful, you can execute the pipeline by running the following command:</p> Execution<pre><code>snakemake --profile profiles/profile_local/\n\n# Alternative: Run pipeline in background &amp; write logs to a specified file\nnohup snakemake --profile profiles/profile_local &amp;&gt; output-$(date +\"%Y-%m-%dT%H-%M-%S\").txt &amp;\n</code></pre>"},{"location":"getting_started/tutorial_splicing/#44-results-html-report","title":"4.4 Results &amp; HTML report","text":"<p>The results of the splicing pattern analysis are stored in the <code>output/module4_splicing_pattern_analysis/output/</code> directory. Feel free to explore the results directly in your file system.</p>"},{"location":"getting_started/tutorial_splicing/#45-troubleshooting","title":"4.5 Troubleshooting","text":"<p>Did you encounter any issues during the execution of the SnakeSplice pipeline? Here are some common issues and possible solutions:</p> <p>1. Problems with Leafcutter container: User namespace Error message<pre><code>FATAL: while extracting [...].snakemake/singularity/6a375c3a043145beefdd13e360f324de.simg:  \nroot filesystem extraction failed:  \nextract command failed:  \nERROR : Failed to create user namespace: user namespace disabled : exit status 1\n</code></pre></p> <p>The error message you're seeing suggests that user namespaces are disabled on your system.  User namespaces are a feature of the Linux kernel that Singularity uses to provide container functionality.</p> <p>Possible Solution:  Was singularity installed correctly?  Simply installing it with conda does not guarantee that it will work correctly. Solution: Install Singularity from the official website: Singularity Installation or use <code>sudo dnf install singularity-ce</code>.</p> <p>2. Problems with Leafcutter container: Missing files Error message<pre><code>IOError: [Errno 2] No such file or directory: 'output/module4_splicing_patterns_analysis/output/leafcutter/leafcutter_output/Bud13_Variant/juncfiles.txt' \n</code></pre></p> <p>Normally Snakemake takes care of providing all required files to the docker container (usually the whole working directory is made available). However, corner cases exists:  - Soft links are not supported</p> <p>Suggestion:  Do not use soft links as input our output!</p> <p>3. Problems with Leafcutter container: No space left Error message<pre><code>FATAL ERROR: write_file: failed to create file /image/root/usr/local/lib/R/site-library/BH/include/boost/thread/once.hpp, because No space left on device: exit status 1' \n</code></pre></p> <p>Sometimes the docker daemon will accumulate a lot of data without really needing it. Thus, the system is blocked with useless data garbage.</p> <p>Suggestion:  You can use pruning to delete all dangling data (containers, networks, and images), which are not under current usage:  <code>docker system prune --all</code></p>"},{"location":"getting_started/tutorial_splicing/#46-celebrate","title":"4.6 Celebrate","text":"<p>Hooray! The SnakeSplice pipeline has been executed successfully and the results of the splicing pattern analysis are ready for exploration.</p> <p>Actually,... ...we are not quite done yet. The last module of SnakeSplice is a special one. It is the module that provides you with the final report of the SnakeSplice pipeline. So, no time to rest yet!</p> <p>Please continue with the tutorial to discover the creation of final reports with SnakeSplice: Report Generation.</p>"},{"location":"swp2024/knatterton/","title":"Knatterton - Let's SnakeSplice","text":"<p>Hey Leute, diese Seite ist die ma\u00dfgeschneiderte Dokumentation f\u00fcr euch! Hier werde ich euch erkl\u00e4ren, wie ihr am besten SnakeSplice auf unserem \"Knatterton\"-Server benutzt.</p>"},{"location":"swp2024/knatterton/#1-installation","title":"1. Installation","text":"<p>Alle Installationsschritte sind bereits im Tutorial beschrieben.</p> <p>Bitte geht daf\u00fcr auf die Tutorial-Seite \"Installation\" und folgt den Anweisungen. Danach kehrt danach einfach hierher zur\u00fcck.</p>"},{"location":"swp2024/knatterton/#2-test-datensatze","title":"2. Test-Datens\u00e4tze","text":"<p>Es gibt leider ein Problem mit dem STAR-Aligner auf unserem Server, sodass invalide BAM-Dateien erzeugt werden. Deswegen habe ich euch die BAM-files schon vorgeneriert und auf dem Server abgelegt. Ihr k\u00f6nnt die fertig-generierten BAM files also direkt verwenden, ohne die Alignierung selbst durchzuf\u00fchren.</p> <p>Insgesamt sind diese Dateien f\u00fcr euch unter <code>/home/sharedFolder/</code> verf\u00fcgbar:</p> <ul> <li><code>star</code> - Ordner mit den fertigen BAM-Dateien</li> <li><code>simulated_reads_chr21_controls_selected</code> - Ordner mit den simulierten Reads der Kontrollgruppe</li> <li><code>simulated_reads_chr21_cases_selected</code> - Ordner mit den simulierten Reads der Fallgruppe</li> </ul> <p>Damit die BAM-files aus dem <code>star</code>-Ordner verwendet werden, ist es am einfachsten den Ordner in euren SnakeSplice-Ordner zu kopieren. Daf\u00fcr k\u00f6nnt ihr folgenden Befehl verwenden:</p> Copy BAM files<pre><code># Erstellt zuerst den Ordner und kopiert dann die BAM-Dateien\nmkdir -p /home/username/snakesplice/output/module1_qc_preproc_and_alignment/output/\ncp -r /home/sharedFolder/star /home/username/snakesplice/output/module1_qc_preproc_and_alignment/output/\n</code></pre> <p>Tipp</p> <p>Anstatt neben den BAM-Files auch die FASTQ-Daten in euren SnakeSplice Ordner zu kopieren, k\u00f6nnt ihr auch einfach  die Pfade in eurer <code>pep/pep_config.yaml</code> Datei anpassen (siehe n\u00e4chster Tipp).</p> <p>input_metadata.csv &amp; pep_config.yaml</p> <p>Bitte denkt daran, die <code>input_metadata.csv</code> und <code>pep_config.yaml</code> Dateien entsprechend anzupassen. Ihr k\u00f6nnt die Dateien auch hier runterladen: input_metadata.csv und pep_config.yaml.</p>"},{"location":"swp2024/knatterton/#3-snakemake-austricksen","title":"3. Snakemake austricksen","text":"<p>Damit Snakemake die fertigen BAM-Dateien nicht nochmal generiert, m\u00fcssen wir ein wenig tricksen. Dabei f\u00fchren wir die Tools in zwei Schritten aus:</p> <ol> <li>Zuerst f\u00fchren wir nur <code>trimmomatic</code> und <code>fastqc</code> aus.</li> <li>Danach f\u00fchren wir einen <code>--touch</code> aus, um die BAM-Dateien als fertig zu markieren.</li> <li>Abschlie\u00dfend f\u00fchren wir die restlichen Tools aus.</li> </ol>"},{"location":"swp2024/knatterton/#31-trimmomatic-fastqc","title":"3.1 Trimmomatic &amp; FastQC","text":"<p>Zuerst wollen wir lediglich <code>trimmomatic</code> &amp; <code>fastqc</code> ausf\u00fchren, um die Qualit\u00e4t der Reads zu \u00fcberpr\u00fcfen.</p> Configuration - Only Trimmomatic &amp; FastQC<pre><code>[...]\n# ------- 1.1 Module: Quality-Control, Preprocessing, and Alignment --------\nmodule1_qc_preprocessing_and_alignment_settings:\n  switch_variables:\n    # Switch variables to decide which features are to be included\n    run_check_of_strandedness: False      # Run python script to check strandedness of input read files\n    run_trimmomatic: True                # Run trimmomatic: Quality trimming of input reads\n    run_kraken2: False                    # Run Kraken2: Check for potential contamination via Kraken2\n    run_fastqc_before_trimming: True      # Run fastqc: Quality control of input reads before trimming\n    run_fastqc_after_trimming: True       # Run fastqc: Quality control of input reads after trimming\n    run_alignment:\n      use_star: False                     # Run STAR alignment: Align reads to reference genome\n      use_olego: False                    # Run Olego alignment: Align reads to reference genome\n    run_bamstats: False                  # Run bamstats: Quality control of aligned reads\n    run_qualimap: False                   # Run Qualimap: Quality control of alignment results\n    run_deeptools: False                  # Run deeptools: Quality control of alignment results\n    run_multiqc: False                     # Run multiqc: Summarize all quality control results into one output-file\n[...]\n</code></pre> <p>F\u00fchre dazu nun den Snakemake Befehl aus:</p> Run SnakeSplice Mod1 - Only Trimmomatic &amp; FastQC<pre><code>snakemake --profile profiles/profile_local\n</code></pre>"},{"location":"swp2024/knatterton/#32-einen-touch-ausfuhren","title":"3.2 Einen Touch ausf\u00fchren","text":"<p>Nachdem dieser Schritt abgeschlossen ist, k\u00f6nnen wir die restlichen Tools aktivieren und f\u00fchren einen <code>--touch</code> aus, um die fertigen BAM-Dateien zu markieren.</p> Configuration - All Tools<pre><code>[...]\n# ------- 1.1 Module: Quality-Control, Preprocessing, and Alignment --------\nmodule1_qc_preprocessing_and_alignment_settings:\n  switch_variables:\n    # Switch variables to decide which features are to be included\n    run_check_of_strandedness: False      # Run python script to check strandedness of input read files\n    run_trimmomatic: True                # Run trimmomatic: Quality trimming of input reads\n    run_kraken2: False                    # Run Kraken2: Check for potential contamination via Kraken2\n    run_fastqc_before_trimming: True      # Run fastqc: Quality control of input reads before trimming\n    run_fastqc_after_trimming: True       # Run fastqc: Quality control of input reads after trimming\n    run_alignment:\n      use_star: True                     # Run STAR alignment: Align reads to reference genome\n      use_olego: False                    # Run Olego alignment: Align reads to reference genome\n    run_bamstats: True                  # Run bamstats: Quality control of aligned reads\n    run_qualimap: True                   # Run Qualimap: Quality control of alignment results\n    run_deeptools: False                  # Run deeptools: Quality control of alignment results\n    run_multiqc: True                     # Run multiqc: Summarize all quality control results into one output-file\n[...]\n</code></pre> <p>Die Ausf\u00fchrung des <code>--touch</code> Befehls markiert die BAM-Dateien als fertig und verhindert, dass sie erneut generiert werden.</p> Run SnakeSplice Mod1 - Touch BAM files<pre><code>snakemake --profile profiles/profile_local --touch\n</code></pre>"},{"location":"swp2024/knatterton/#33-restliche-tools-ausfuhren","title":"3.3 Restliche Tools ausf\u00fchren","text":"<p>Dananach k\u00f6nnen wir die restlichen Tools ausf\u00fchren, ohne dass die BAM-Dateien erneut generiert werden. Daf\u00fcr reicht es, den normalen Snakemake Befehl auszuf\u00fchren.</p> Run SnakeSplice Mod1 - All selected Tools<pre><code>snakemake --profile profiles/profile_local\n</code></pre>"},{"location":"swp2024/knatterton/#4-fertig","title":"4. Fertig!","text":"<p>Das war's auch schon! Ihr habt nun erfolgreich SnakeSplice auf unserem \"Knatterton\"-Server ausgef\u00fchrt. Doch das war erst der Anfang. Drei weitere Module warten auf euch, um eure Daten zu analysieren. Also nichts wie los!</p> <p>Hier geht's weiter zum n\u00e4chsten Modul.</p>"}]}